---
title: "HW 03 - Exploring the GSS"
author: "Micaiah Balonek"
date: "March 26"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  eval = TRUE,
  out.width = "80%",
  fig.asp = 0.618,
  fig.width = 10,
  dpi = 300
)
```

```{r photo,  echo = FALSE, fig.width = 3, fig.cap = "Photo by Mauro Mora on Unsplash", eval = TRUE}
knitr::include_graphics("img/mauro-mora-31-pOduwZGE-unsplash.jpg")
```

The GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviours, and attributes.
Hundreds of trends have been tracked since 1972.
In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.

The GSS contains a standard core of demographic, behavioural, and attitudinal questions, plus topics of special interest.
Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.

In this assignment we analyze data from the 2016 GSS, using it to estimate values of population parameters of interest about US adults.[^hw-08-exploring-gss-1]


## Warm up

Before we introduce the data, let's warm up with some simple exercises.
Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
Make sure to commit with a meaningful commit message.
Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
If anything is missing, commit and push again.

## Packages

We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.

You will need to install the packages and to install dsbox copy the following code into the console: 

```
install.packages("devtools")
devtools::install_github("tidyverse/dsbox")
```

You can load them by running the following in your Console:

```{r load-packages, message = FALSE, eval = TRUE}
library(tidyverse)
library(dsbox)
library(tidymodels)
library(flextable)
```

## Data

The data can be found in the **dsbox** package, and it's called `gss16`.
Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
You can find out more about the dataset by inspecting its documentation, which you can access by running `?gss16` in the Console or using the Help menu in RStudio to search for `gss16`.
You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/gss16.html).

# Exercises

## Part 1: Harassment at work

In 2016, the GSS added a new question on harassment at work.
The question is phrased as the following.

> *Over the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?*

Answers to this question are stored in the `harass5` variable in our dataset.

1.  What are the possible responses to this question and how many respondents chose each of these answers?

```{r harassment-count}
gss16 %>%
  count(harass5) %>%
  flextable() %>% autofit()
```

- *There are three possible answers: 'Yes', 'No', and 'Does not apply (i do not have a job/superior/co-worker)'. `r count(filter(gss16, harass5 == "Yes"))#n` people responded 'yes', `r count(filter(gss16, harass5 == "No"))#n` people responded 'no', `r count(filter(gss16, harass5 == "Does not apply (i do not have a job/superior/co-worker)"))#n` people responded 'does not apply', and `r count(filter(gss16, is.na(harass5)))#n` people either did not respond or have missing data for some other reason.*

2.  What percent of the respondents for whom this question is applicable\
    (i.e. excluding `NA`s and `Does not apply`s) have been harassed by their superiors or co-workers at their job.

```{r harassment-percent}
gss16 %>%
  filter(harass5 == "Yes" | harass5 == "No") %>%
  count(harass5, total = n()) %>%
  mutate(percent = n/total*100, .keep = "unused") %>%
  flextable() %>% autofit()
  
```

- *Of the applicable people who responded to this question, 17% had been harassed at their job.*

üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*

## Part 2: Time spent on email

The 2016 GSS also asked respondents how many hours and minutes they spend on email weekly.
The responses to these questions are recorded in the `emailhr` and `emailmin` variables.
For example, if the response is 2.5 hrs, this would be recorded as `emailhr = 2` and `emailmin = 30`.

3.  Create a new variable called `email` that combines these two variables to reports the number of minutes the respondents spend on email weekly.

```{r email-time}
gss16 <- gss16 %>%
  mutate(email = emailmin + emailhr*60)
```

4.  Visualize the distribution of this new variable.
    Find the mean and the median number of minutes respondents spend on email weekly.
    Is the mean or the median a better measure of the typical among of time Americans spend on email weekly?
    Why?

```{r email-distribution}
gss16 %>%
  ggplot(aes(x = email)) +
  geom_histogram(binwidth = 60) +
  theme_minimal() +
  labs(title = "Distribution of hours spent on email per week", x = "Hours spent on email per week")

gss16 %>%
  filter(!is.na(email)) %>%
  summarise(mean(email), median(email)) %>%
  flextable() %>% autofit()
```

- *The distribution consistently increases in peak height closer to 0, with a few notable outliers, which skew the mean to be a disproportionately large value. Therefore, the median is the more accurate summary statistic.*

5.  Create another new variable, `snap_insta` that is coded as "Yes" if the respondent reported using any of Snapchat (`snapchat`) or Instagram (`instagrm`), and "No" if not.
    If the recorded value was `NA` for both of these questions, the value in your new variable should also be `NA`.

```{r snap-insta-var}
gss16 <- gss16 %>% 
  mutate(snap_insta = case_when(
    is.na(snapchat) & is.na(instagrm) ~ NA,
    snapchat == "Yes" | instagrm == "Yes" ~ "Yes",
    TRUE ~ "No"
  ))
```

6.  Calculate the percentage of Yes's for `snap_insta` among those who answered the question, i.e. excluding `NA`s.

```{r snap-insta-percent}
gss16 %>%
  filter(!is.na(snap_insta)) %>%
  count(snap_insta) %>%
  mutate(snap_insta_percent = 100*n/sum(n), .keep = "unused") %>%
  flextable() %>% autofit()
```

- *About 63% of people who responded answered that they didn't use  instagram or snapchat, and about 37% answered that they used at least one of them.*

7.  What are the possible responses to the question *Last week were you working full time, part time, going to school, keeping house, or what?* and how many respondents chose each of these answers?
    Note that this information is stored in the `wrkstat` variable.

```{r wrkstat-analysis}
gss16 %>% 
  filter(!is.na(wrkstat)) %>%
  count(wrkstat) %>%
  flextable() %>% autofit()
```

- *In response to this question, 284 people responded that they were keeping house, 574 that they were retired, 76 that they were going to school, 57 that they were temporarily not working, 118 that they were unemployed because they had been laid off, 345 that they were working part-time, 1,321 that they were working full-time, and 89 said that none of the other options applied to them.*

8.  Fit a model predicting `email` (number of minutes per week spent on email) from `educ` (number of years of education), `wrkstat`, and `snap_insta`.
    Interpret the slopes for each of these variables.

```{r email-predict-model}
email_model <- linear_reg() %>%
  set_engine("lm") %>%
  fit(email~educ + wrkstat + snap_insta, data = gss16) %>% tidy()

email_model %>%
  flextable() %>% autofit()
```
- *What this model suggests is that, all else held constant, for every additional year of education someone has, they will spend half an hour more on emails per week than they would otherwise. In addition, each job-type has its own general amount of weekly email-time past the base-level amount. This is 68 minutes for retired people, -124 minutes (i.e. that many minutes less) for people in school, -74 minutes for people who are temporarily not working, 118 more minutes for people who have been laid off, 367 minutes for people working fulltime (although only 19 minutes for people working parttime), and 33 minutes otherwise. In addition people who use snapchat or instagram use email for, on average, 150 more minutes per week than equivalent people who don't.*


9.  Create a predicted values vs. residuals plot for this model.
    Are there any issues with the model?
    If yes, describe them.

```{r email-residual-plot, warning=FALSE}

gss16_email_resid <- gss16 %>%
  mutate(predicted_email = filter(email_model, term == "(Intercept)")$estimate + educ*filter(email_model, term == "educ")$estimate + as.numeric(snap_insta == "Yes")*filter(email_model, term == "snap_instaYes")$estimate + case_when(
    wrkstat == "Retired" ~ 68.27922,
    wrkstat == "School" ~ -123.81216,
    wrkstat == "Temp not working" ~ -73.70850,
    wrkstat == "Unempl, laid off" ~ 118.34913,
    wrkstat == "Working fulltime" ~ 366.84029,
    wrkstat == "Working parttime" ~ 18.90036,
    wrkstat == "Other" ~ 33.05657
  ), email_residual = email - predicted_email) 

gss16_email_resid %>%
  filter(!is.na(email_residual)) %>%
  ggplot(aes(x = educ, shape = snap_insta, linetype = snap_insta)) +
  geom_point(aes(y = predicted_email), size = 2, colour = "orange") +
  geom_smooth(aes(y = predicted_email), colour = "orange") +
  geom_point(aes(y = abs(email_residual)), size = 2, colour = "blue", ) +
  facet_wrap(~ wrkstat) + 
  labs(title = "Predicted values of email vs. remainders by years of education", subtitle = "orange: model predictions, blue: remainders", shape = "Use of instagram and/or snapchat", linetype = "Use of instagram and/or snapchat")

gss16_email_resid %>%
  filter(email_residual >= predicted_email) %>% 
  select(email, predicted_email, email_residual, educ, snap_insta, wrkstat) %>%
  slice_head(n = 20) %>%
  flextable() %>% autofit()
```

- *This model consistently has residuals at or above the value the model predicts; just examining the statistics of the points with residuals above the modeled function doesn't show any clear patterns in which ones are predicted with the most problems. While most are in the `wrkstat` category 'Working fulltime', but that is also true of the rest of the data as well. More analysis would be necessary to find a better model for this data.*

üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*

## Part 3: Political views and science research

The 2016 GSS also asked respondents whether they think of themselves as liberal or conservative (`polviews`) and whether they think science research is necessary and should be supported by the federal government (`advfront`).

-   The question on science research is worded as follows:

> Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.

And possible responses to this question are Strongly agree, Agree, Disagree, Strongly disagree, Don't know, No answer, Not applicable.

-   The question on political views is worded as follows:

> We hear a lot of talk these days about liberals and conservatives.
> I'm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal--point 1--to extremely conservative--point 7.
> Where would you place yourself on this scale?


**Note:** The levels of this variables are spelled inconsistently: "Extremely liberal" vs. "Extrmly conservative". Since this is the spelling that shows up in the data, you need to make sure this is how you spell the levels in your code.


And possible responses to this question are Extremely liberal, Liberal, Slightly liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative.
Responses that were originally Don't know, No answer and Not applicable are already mapped to `NA`s upon data import.

10. In a new variable, recode `advfront` such that Strongly Agree and Agree are mapped to `"Yes"`, and Disagree and Strongly disagree are mapped to `"No"`.
    The remaining levels can be left as is.
    Don't overwrite the existing `advfront`, instead pick a different, informative name for your new variable.

```{r adv-releveling}

gss16 <- gss16 %>%
  mutate(adv_yesno = factor(advfront, levels = c("Strongly agree", "Agree", "Dont know", "Disagree", "Strongly disagree"),
         labels = c("Yes", "Yes", "Dont know", "No", "No")))

```

11. In a new variable, recode `polviews` such that Extremely liberal, Liberal, and Slightly liberal, are mapped to `"Liberal"`, and Slghtly conservative, Conservative, and Extrmly conservative disagree are mapped to `"Conservative"`.
    The remaining levels can be left as is.
    Make sure that the levels are in a reasonable order.
    Don't overwrite the existing `polviews`, instead pick a different, informative name for your new variable.

```{r polviews-releveling}
gss16 <- gss16 %>%
  mutate(polviews_simple = factor(polviews, levels = c("Extremely liberal", "Liberal", "Slightly liberal", "Moderate", "Slghtly conservative", "Conservative", "Extrmly conservative"),
         labels = c("Liberal", "Liberal", "Liberal", "Moderate", "Conservative", "Conservative", "Conservative")))

```

12. Create a visualization that displays the relationship between these two new variables and interpret it.

```{r polviews-adv-graph}
gss16 %>%
  filter(!is.na(polviews_simple) & !is.na(adv_yesno)) %>%
  ggplot(aes(x = polviews_simple, fill = adv_yesno)) + 
  geom_bar() +
  scale_fill_manual(values = c("#71af40", "#eeeebe", "#dc6d39")) +
  theme_minimal() +
  labs(title = "Opinions on government sponshorship of scientific advancement", subtitle = "By political opinion", fill = "Answer to 'should the government support scientific advancement'", x = "Political view")

gss16 %>%
  filter(!is.na(polviews_simple) & !is.na(adv_yesno)) %>%
  ggplot(aes(x = adv_yesno, fill = polviews_simple)) + 
  geom_bar(position = "fill") +
  scale_fill_manual(values = c("#417fa0", "#dddddd", "#dc6d39")) +
  theme_minimal() +
  labs(title = "Political views by opinions", subtitle = "On whether the government should support scientific advancement", x = "Answer to 'should the government support scientific advancement'", fill = "Political view")
```

- *Here we can see that, within each category, there are many more people that agree science that advances the frontiers of knowledge should be supported by the government than people that don't agree. However, the proportion of people who think that science advancement should not be funded by the government is notably higher in conservatives than in liberals and moderates, as well as the proportion of people who selected that they "don't know". Among people who believe that science should be government-funded, all three groups seem to be roughly equally distributed, with a slightly higher proportion of independents.*

üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

